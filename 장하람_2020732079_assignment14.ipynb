{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy2_q1yA_eY2"
      },
      "source": [
        "# Sequence Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 23.12 update\n",
        "  - torchtext에서 더이상 legacy 문법을 지원하지 않음에 따라 새 버전(0.16.0)에 맞는 문법으로 변경함\n",
        "  - 기존의 legacy 문법에서 black-box 처럼 사용해왔던 함수들을 새 버전에서는 더 자세하게 세팅할 수 있도록 변경되었음\n",
        "  - 그에 따라 코드의 양이 증가하였으나 동작하는 바는 동일함\n",
        "  - pytorch에서 공식적으로 제공하는 문서를 참고하였음\n",
        "    - https://pytorch.org/text/stable/datasets.html\n",
        "    - https://colab.research.google.com/github/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb"
      ],
      "metadata": {
        "id": "rmE1rei2Nc39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install requirement package"
      ],
      "metadata": {
        "id": "bHLAb2V8rUqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'portalocker>=2.0.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSFUFEgCX5Pn",
        "outputId": "95fcc5a8-b17f-4779-905a-c3c9544ff797"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import"
      ],
      "metadata": {
        "id": "OP0evdVqreKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.vocab import vocab\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "# parameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "training_epochs = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKiRUl2Grim4",
        "outputId": "9fd9871e-1216-4a53-8c16-610f79c95d5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 Dataset"
      ],
      "metadata": {
        "id": "hJU_84slte_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter, test_iter = IMDB(split=('train', 'test'))\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "counter = Counter()\n",
        "for (label, line) in train_iter:\n",
        "    counter.update(tokenizer(line))\n",
        "vocab = vocab(counter, min_freq=10, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>'))\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(\"The length of the new vocab is\", vocab_size)\n",
        "new_stoi = vocab.get_stoi()\n",
        "print(\"The index of '<BOS>' is\", new_stoi['<BOS>'])\n",
        "new_itos = vocab.get_itos()\n",
        "print(\"The token at index 2 is\", new_itos[2])\n",
        "\n",
        "text_transform = lambda x: [vocab['<BOS>']] + [vocab[token] if token in new_itos else vocab['<unk>'] for token in tokenizer(x)] + [vocab['<EOS>']]\n",
        "label_transform = lambda x: 0 if x == 1 else 1\n",
        "\n",
        "# Print out the output of text_transform\n",
        "print(\"input to the text_transform:\", \"here is an example\")\n",
        "print(\"output of the text_transform:\", text_transform(\"here is an example\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFNHFyQ2X1zb",
        "outputId": "3dbad042-c86e-41cf-d76d-3656eec0c30d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the new vocab is 20439\n",
            "The index of '<BOS>' is 1\n",
            "The token at index 2 is <EOS>\n",
            "input to the text_transform: here is an example\n",
            "output of the text_transform: [1, 972, 55, 198, 3456, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "   label_list, text_list = [], []\n",
        "   for (_label, _text) in batch:\n",
        "        label_list.append(label_transform(_label))\n",
        "        processed_text = torch.tensor(text_transform(_text))\n",
        "        text_list.append(processed_text)\n",
        "   return torch.tensor(label_list), pad_sequence(text_list, padding_value=3.0)\n",
        "\n",
        "\n",
        "def batch_sampler():\n",
        "    indices = [(i, len(tokenizer(s[1]))) for i, s in enumerate(train_list)]\n",
        "    random.shuffle(indices)\n",
        "    pooled_indices = []\n",
        "    # create pool of indices with similar lengths\n",
        "    for i in range(0, len(indices), batch_size * 100):\n",
        "        pooled_indices.extend(sorted(indices[i:i + batch_size * 100], key=lambda x: x[1]))\n",
        "\n",
        "    pooled_indices = [x[0] for x in pooled_indices]\n",
        "    # yield indices for current batch\n",
        "    for i in range(0, len(pooled_indices), batch_size):\n",
        "        yield pooled_indices[i:i + batch_size]"
      ],
      "metadata": {
        "id": "Qlk-9-qUgzEM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = list(train_iter)\n",
        "random.shuffle(data_list)\n",
        "train_list = data_list[:int(len(data_list)*0.8)]\n",
        "valid_list = data_list[int(len(data_list)*0.8):]\n",
        "test_list = list(test_iter)\n",
        "\n",
        "train_loader = DataLoader(train_list, batch_sampler=batch_sampler(),\n",
        "                               collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(valid_list, batch_size=batch_size, shuffle=True,\n",
        "                              collate_fn=collate_batch)\n",
        "test_loader = DataLoader(test_list, batch_size=batch_size, shuffle=True,\n",
        "                              collate_fn=collate_batch)\n",
        "\n",
        "n_classes = 2 # Positive, Negative Class가 두 개\n",
        "\n",
        "print(\"[TrainSet]: %d [ValSet]: %d [TestSet]: %d [Vocab]: %d [Classes] %d\"\n",
        "      % (len(train_list),len(valid_list), len(test_list), vocab_size, n_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuQBVo_dg0T6",
        "outputId": "178bccbd-0b7e-4270-e67d-0381db3d6e5b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TrainSet]: 20000 [ValSet]: 5000 [TestSet]: 25000 [Vocab]: 20439 [Classes] 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH2RX5pEBB0H"
      },
      "source": [
        "### 2 RNN model\n",
        "* Layer 설계\n",
        "  + Layer 1\n",
        "    - Embedding Layer\n",
        "    - Input size = n_Vocabs = 46159\n",
        "    - Output size = Embedding size\n",
        "  + Layer 2\n",
        "    - GRU Layer\n",
        "    - Input size = Embedding size\n",
        "    - Output size = Hidden size\n",
        "    - Dropout = 0.2\n",
        "  + Layer 3\n",
        "    - Linear Layer\n",
        "    - Input size = Hidden size\n",
        "    - Output size = n_Classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL2ZwVjWBCw7"
      },
      "source": [
        "class BasicGRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(BasicGRU, self).__init__()\n",
        "        self.n_layers = n_layers # 일반적으로는 2\n",
        "\n",
        "        #n_vocab : Vocab 안에 있는 단어의 개수, embed_dim : 임베딩 된 단어 텐서가 갖는 차원 값(dimension)\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "\n",
        "        # hidden vector의 dimension과 dropout 정의\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        #앞에서 정의한 하이퍼 파라미터를 넣어 GRU 정의\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True)\n",
        "\n",
        "        #Input: GRU의 hidden vector(context), Output : Class probability vector\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input data: 한 batch 내 모든 영화 평가 데이터\n",
        "\n",
        "        x = self.embed(x)# 영화 평 임베딩\n",
        "        x, _ = self.gru(x)  # [i, b, h] 출력값 :  (batch_size, 입력 x의 길이, hidden_dim)\n",
        "\n",
        "        # h_t : Batch 내 모든 sequential hidden state vector의 제일 마지막 토큰을 내포한 (batch_size, 1, hidden_dim)형태의 텐서 추출\n",
        "        # 다른 의미로 영화 리뷰 배열들을 압축한 hidden state vector\n",
        "        h_t = x[:,-1,:]\n",
        "\n",
        "        self.dropout(h_t)# dropout 설정 후,\n",
        "\n",
        "        # linear layer의 입력으로 주고, 각 클래스 별 결과 logit을 생성.\n",
        "        out = self.out(h_t)  # [b, h] -> [b, o]\n",
        "        return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjPX7b5A6PA-"
      },
      "source": [
        "### 3 Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6XeYPhI6Tig",
        "outputId": "ca277858-d283-46a0-e56b-4ac1dd9a1633"
      },
      "source": [
        "# contruct model\n",
        "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# train\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    for label, text in train_loader:\n",
        "        print(label)\n",
        "        label = label.to(device)\n",
        "        text = text.transpose(1,0)\n",
        "        text = text.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(text)\n",
        "        print(hypothesis)\n",
        "        cost = criterion(hypothesis, label)\n",
        "        cost.backward()\n",
        "        print(cost)\n",
        "        optimizer.step()\n",
        "        avg_cost += float(cost / batch_size)\n",
        "    print('[Epoch: {:>4}] cost = {:>.9f}'.format(epoch + 1, avg_cost))\n",
        "print('Learning Finished!')\n",
        "\n",
        "# model save\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/model_s1.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] cost = 0.000000000\n",
            "[Epoch:    2] cost = 0.000000000\n",
            "[Epoch:    3] cost = 0.000000000\n",
            "[Epoch:    4] cost = 0.000000000\n",
            "[Epoch:    5] cost = 0.000000000\n",
            "Learning Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoemsR1Qzsze",
        "outputId": "50432d44-66c0-4ef8-a3bc-3cf1a6b059ff"
      },
      "source": [
        "# model load\n",
        "model_new = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n",
        "model_new.load_state_dict(torch.load('/content/drive/MyDrive/model_s1.pt'))\n",
        "\n",
        "corrects = 0\n",
        "for label, text in valid_loader:\n",
        "  label = label.to(device)\n",
        "  text = text.transpose(1,0)\n",
        "  text = text.to(device)\n",
        "  hypothesis = model_new(text)\n",
        "  corrects += (hypothesis.max(1)[1].view(label.size()).data == label.data).sum()\n",
        "\n",
        "print('accuracy = ', corrects/len(valid_list)*100.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy =  tensor(73.4400, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc6TPzluWB1M"
      },
      "source": [
        "### 4 Assignment\n",
        "##### a) 아래 예제 코드를 이용해 텍스트 입력의 숫자 변환 과정을 체크한다\n",
        "##### b) testset의 임의 입력을 학습 완료된 모델에 입력해보고, 결과가 어떠한지 체크한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "ie20dbcX51N5",
        "outputId": "5967ae62-8acd-42e4-bfbf-9eb8542e450a"
      },
      "source": [
        "# 'text_transform'이라는 함수가 텍스트를 정수로 변환한다고 가정하겠습니다.\n",
        "input_text = \"movie good\"\n",
        "print(\"Original text:\", input_text)\n",
        "transformed_text = text_transform(input_text)\n",
        "print(\"Transformed text (as numbers):\", transformed_text)\n",
        "# 이전에 정의한 함수를 사용하여 입력 텍스트를 적절한 형식(숫자)으로 변환합니다.\n",
        "input_text = \"movie good\"\n",
        "numerical_input = text_transform(input_text)\n",
        "numerical_input = torch.tensor(numerical_input)  # PyTorch Tensor로 변환\n",
        "numerical_input = numerical_input.unsqueeze(0).to(device)  # 배치 차원 추가하고 device로 보내기\n",
        "\n",
        "# 추론 전에 모델이 eval 모드에 있는지 확인해야 합니다.\n",
        "model_new = torch.load('/content/drive/MyDrive/model_s1.pt')\n",
        "model_new.eval()  # 모델을 평가 모드로 설정합니다.\n",
        "\n",
        "# 입력을 모델을 통해 전달합니다.\n",
        "with torch.no_grad():  # 이 블록에서 그래디언트가 계산되지 않도록 합니다.\n",
        "    output = model_new(numerical_input)\n",
        "\n",
        "print(\"Model's Logits Output:\", output)\n",
        "\n",
        "# 로짓에 argmax를 적용하여 예측된 클래스를 얻습니다.\n",
        "predicted_class = torch.argmax(output, axis=1)\n",
        "print(\"Predicted class index:\", predicted_class.item())\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: movie good\n",
            "Transformed text (as numbers): [0, 1]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2a0cfb73d321>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 추론 전에 모델이 eval 모드에 있는지 확인해야 합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/model_s1.pt'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 'model_path.pth'는 모델의 가중치를 저장한 파일 경로입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 모델을 평가 모드로 설정합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 입력을 모델을 통해 전달합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
          ]
        }
      ]
    }
  ]
}